{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616a18f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('demo/현대해상3(퇴직연금)상품약관.txt', 'r') as file:\n",
    "    text = file.read()\n",
    "\n",
    "# print(text[:512])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b75783",
   "metadata": {},
   "source": [
    "1) **Building**: RAPTOR recursively embeds, clusters, and summarizes chunks of text to construct a tree with varying levels of summarization from the bottom up. You can create a tree from the text in 'sample.txt' using `RA.add_documents(text)`.\n",
    "\n",
    "2) **Querying**: At inference time, the RAPTOR model retrieves information from this tree, integrating data across lengthy documents at different abstraction levels. You can perform queries on the tree with `RA.answer_question`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a864f460",
   "metadata": {},
   "source": [
    "### Building the tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1817043d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.llm_manager import AzureAIClientManager\n",
    "from raptor.EmbeddingModels import AzureEmbeddingModel\n",
    "from raptor.SummarizationModels import AzureSummarizationModel\n",
    "from raptor.QAModels import AzureQAModel\n",
    "from raptor import RetrievalAugmentation, RetrievalAugmentationConfig\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# 1) Azure 클라이언트 매니저 설정\n",
    "azure_emb_client = AzureAIClientManager(\n",
    "    endpoint= os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_KEY\"),\n",
    "    deployment=\"text-embedding-3-large\"      # ↖ 임베딩 전용\n",
    ")\n",
    "emb_model = AzureEmbeddingModel(azure_emb_client)\n",
    "\n",
    "azure_chat_client = AzureAIClientManager(\n",
    "    endpoint= os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_KEY\"),\n",
    "    deployment=\"gpt-4o\"                      # ↖ chat 전용\n",
    ")\n",
    "sum_model = AzureSummarizationModel(azure_chat_client)\n",
    "qa_model  = AzureQAModel(azure_chat_client)\n",
    "\n",
    "\n",
    "# 3) RAPTOR 설정에 주입\n",
    "cfg = RetrievalAugmentationConfig(\n",
    "    embedding_model=emb_model,\n",
    "    summarization_model=sum_model,\n",
    "    qa_model=qa_model,\n",
    "    tb_max_tokens=512,\n",
    "    tb_summarization_length=512\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b536b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) RAPTOR 실행\n",
    "RA = RetrievalAugmentation(config=cfg)\n",
    "RA.add_documents(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac9e42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from raptor.visualize import visualize_tree_structure\n",
    "from raptor.tree_structures import Node, Tree\n",
    "import random, string\n",
    "from typing import List\n",
    "\n",
    "tree = RA.tree\n",
    "# Now create a new root Node on top of all root nodes\n",
    "root_node = Node(\n",
    "    \"Tree Root\",\n",
    "    index=-1,\n",
    "    children=list(map(lambda x: x.index, tree.root_nodes.values())),\n",
    "    embeddings=[],\n",
    ")\n",
    "visualize_tree_structure(root_node, tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3667bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) 간단한 임베딩 확인\n",
    "vec = emb_model.create_embedding(\"hello world\")\n",
    "print(f\"벡터 차원: {len(vec)}  예시값: {vec[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86c8088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) 중간 컨텍스트 확인\n",
    "ctx, layers = RA.retrieve(\"How did Cinderella reach her happy ending?\", return_layer_information=True)\n",
    "print(\"선택된 컨텍스트:\", ctx[:200].replace(\"\\n\",\" \"))\n",
    "print(\"ctx length:\", len(ctx))\n",
    "print(\"레이어 정보:\", layers)\n",
    "print(\"레이어 정보 길이:\", len(layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096452df",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"이율적용형 이율 비율\"\n",
    "root_node = Node(\n",
    "    query,\n",
    "    index=-1,\n",
    "    children=[n.index for n in tree.root_nodes.values()],\n",
    "    embeddings=[],\n",
    ")\n",
    "\n",
    "ctx, layers = RA.retrieve(query, return_layer_information=True)\n",
    "highlight = [info[\"node_index\"] for info in layers]\n",
    "\n",
    "visualize_tree_structure(root_node, tree,\n",
    "                         highlight_node_indices=highlight,\n",
    "                         highlight_color=\"#e74c3c\")   # 빨간색 하이라이트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd281e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from raptor.visualize import visualize_tree_structure_pyvis\n",
    "\n",
    "# visualize_tree_structure_pyvis(\n",
    "#     root_node,\n",
    "#     tree,\n",
    "#     highlight_node_indices=highlight,\n",
    "#     highlight_color=\"#e74c3c\",   # 빨강\n",
    "#     output_file=\"tree.html\",     # 생성 HTML\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94829968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7) 실제 QA\n",
    "answer, layers = RA.answer_question(\"이율적용형 이율 비율\", return_layer_information=True)\n",
    "print(\"Answer:\", answer)\n",
    "print(\"레이어 정보:\", layers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "raptor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
